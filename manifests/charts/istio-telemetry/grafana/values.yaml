grafana:
  enabled: true
  replicaCount: 1
  image:
    repository: grafana/grafana
    tag: 7.0.3
  persist: false
  storageClassName: ""
  accessMode: ReadWriteMany
  security:
    enabled: false
    secretName: grafana
    usernameKey: username
    passphraseKey: passphrase

  contextPath: /grafana
  service:
    annotations: {}
    name: http
    type: ClusterIP
    externalPort: 3000
    loadBalancerIP: ""
    loadBalancerSourceRanges: ""

  ingress:
    enabled: false
    ## Used to create an Ingress record.
    hosts:
      - grafana.local
    annotations:
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    tls:
      # Secrets must be manually created in the namespace.
      # - secretName: grafana-tls
      #   hosts:
      #     - grafana.local

  # Optional: prometheus may be deployed in a different namespace
  # prometheusNamespace: istio-telemetry

  # Additional datasources. Prometheus included in the config map.
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
      - name: Prometheus
        type: prometheus
        orgId: 1
        url: http://prometheus:9090
        access: proxy
        isDefault: true
        jsonData:
          timeInterval: 5s
        editable: true

  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'istio'
          orgId: 1
          folder: 'istio'
          type: file
          disableDeletion: false
          options:
            path: /var/lib/grafana/dashboards/istio

  nodeSelector: {}
  tolerations: []
  podAnnotations: {}

  env: {}
    # Define additional environment variables for configuring grafana.
    # @see https://grafana.com/docs/installation/configuration/#using-environment-variables
    # Format: env_variable_name: value
    # For example:
    # GF_SMTP_ENABLED: true
    # GF_SMTP_HOST: email-smtp.eu-west-1.amazonaws.com:2587
    # GF_SMTP_FROM_ADDRESS: alerts@mydomain.com
    # GF_SMTP_FROM_NAME: Grafana
  
  envSecrets: {}
    # The key name and ENV name must match in the secrets file.
    # @see https://grafana.com/docs/installation/configuration/#using-environment-variables
    # For example:
    # ---
    # apiVersion: v1
    # kind: Secret
    # metadata:
    #   name: grafana-secrets
    #   namespace: istio-system
    # data:
    #   GF_SMTP_USER: bXl1c2Vy
    #   GF_SMTP_PASSWORD: bXlwYXNzd29yZA==
    # type: Opaque
    # ---
    # env_variable_key_name: secretsName
    # ---
    # GF_SMTP_USER: grafana-secrets
    # GF_SMTP_PASSWORD: grafana-secrets

  resources: {}

  prometheusNamespace: ""

  # Specify the pod anti-affinity that allows you to constrain which nodes
  # your pod is eligible to be scheduled based on labels on pods that are
  # already running on the node rather than based on labels on nodes.
  # There are currently two types of anti-affinity:
  #    "requiredDuringSchedulingIgnoredDuringExecution"
  #    "preferredDuringSchedulingIgnoredDuringExecution"
  # which denote "hard" vs. "soft" requirements, you can define your values
  # in "podAntiAffinityLabelSelector" and "podAntiAffinityTermLabelSelector"
  # correspondingly.
  # For example:
  # podAntiAffinityLabelSelector:
  # - key: security
  #   operator: In
  #   values: S1,S2
  #   topologyKey: "kubernetes.io/hostname"
  # This pod anti-affinity rule says that the pod requires not to be scheduled
  # onto a node if that node is already running a pod with label having key
  # "security" and value "S1".
  podAntiAffinityLabelSelector: []
  podAntiAffinityTermLabelSelector: []

global:
  # Specify pod scheduling arch(amd64, ppc64le, s390x) and weight as follows:
  #   0 - Never scheduled
  #   1 - Least preferred
  #   2 - No preference
  #   3 - Most preferred
  arch:
    amd64: 2
    s390x: 2
    ppc64le: 2

  # Default node selector to be applied to all deployments so that all pods can be
  # constrained to run a particular nodes. Each component can overwrite these default
  # values by adding its node selector block in the relevant section below and setting
  # the desired values.
  defaultNodeSelector: {}

  # A minimal set of requested resources to applied to all deployments so that
  # Horizontal Pod Autoscaler will be able to function (if set).
  # Each component can overwrite these default values by adding its own resources
  # block in the relevant section below and setting the desired resources values.
  defaultResources:
    requests:
      cpu: 10m
    #   memory: 128Mi
    # limits:
    #   cpu: 100m
    #   memory: 128Mi

  # Default node tolerations to be applied to all deployments so that all pods can be
  # scheduled to a particular nodes with matching taints. Each component can overwrite
  # these default values by adding its tolerations block in the relevant section below
  # and setting the desired values.
  # Configure this field in case that all pods of Istio control plane are expected to
  # be scheduled to particular nodes with specified taints.
  defaultTolerations: []

  # Specifies whether helm test is enabled or not.
  # This field is set to false by default, so 'helm template ...'
  # will ignore the helm test yaml files when generating the template
  enableHelmTest: false

  # Default hub for Istio images.
  # Releases are published to docker hub under 'istio' project.
  # Dev builds from prow are on gcr.io
  hub: gcr.io/istio-testing

  # Default tag for Istio images.
  tag: latest

  # Specify image pull policy if default behavior isn't desired.
  # Default behavior: latest images will be Always else IfNotPresent.
  imagePullPolicy: ""

  # ImagePullSecrets for all ServiceAccount, list of secrets in the same namespace
  # to use for pulling any images in pods that reference this ServiceAccount.
  # For components that don't use ServiceAccounts (i.e. grafana, servicegraph, tracing)
  # ImagePullSecrets will be added to the corresponding Deployment(StatefulSet) objects.
  # Must be set for any cluster configured with private docker registry.
  imagePullSecrets: []
  # - private-registry-key

  # Kubernetes >=v1.11.0 will create two PriorityClass, including system-cluster-critical and
  # system-node-critical, it is better to configure this in order to make sure your Istio pods
  # will not be killed because of low priority class.
  # Refer to https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass
  # for more detail.
  priorityClassName: ""

  proxy:
    image: proxyv2
